# Jarvis â€” Streamlit UI (shadcn-like)

![Interface â€“ Jarvis UI](docs/interface.png)

> _Assistant vocal + chat local avec Whisper/Faster-Whisper, Piper TTS, Ollama et outils MCP (DuckDuckGo, fetch, etc.)._

---

## âœ¨ FonctionnalitÃ©s

- **Interface moderne** (Streamlit) avec topbar dâ€™Ã©tat (WHISPER, PIPER, OLLAMA, MCP, ONNXRT).
- **Radar vocal** animÃ© (SVG) rendu via un composant **HTML/JS** isolÃ©. Les ondes se dÃ©clenchent quand lâ€™assistant Â« parle Â» (basÃ© sur les logs), prÃªt Ã  Ãªtre branchÃ© sur un vrai **niveau RMS**.
- **Chat + Raccourcis** : `/web`, `/ddg`, `/fetch`, `!tool <name> {json}`.
- **Websearch MCP** (client stdio Ã©phÃ©mÃ¨re) : DuckDuckGo search/fetch, auto-web option.
- **ContrÃ´les audio** : prÃ©fÃ©rences TTS (Piper), langue, vitesse, speaker id, CUDA on/off.
- **Gestion des serveurs MCP** : dÃ©marrer/stopper, lister les tools, exÃ©cuter un tool.
- **Ollama** : test de connexion, pull/warmup, choix de modÃ¨le.
- **Persistance** : configuration stockÃ©e sous `~/.jarvis/ui_config.json`.

---

## ğŸ§° PrÃ©requis

- Python **3.11** recommandÃ©
- **Ollama** (local) pour les LLMs
- **Piper** (pour TTS) + voix `.onnx`
- (Optionnel) **modelcontextprotocol / mcp** pour le client MCP Python
- Node.js (si vous utilisez le **proxy MCP** `adamwattis_mcp-proxy-server`)

---

## ğŸš€ Installation

```bash
# 1) CrÃ©ez un venv
python -m venv .venv
source .venv/bin/activate  # ou .venv\\Scripts\\activate sous Windows

# 2) DÃ©pendances Python
pip install streamlit requests onnxruntime  # + mcp si besoin: pip install mcp

# 3) Lancer l'UI
streamlit run app_4.py
```

> **Astuce** : si vous utilisez **onnxruntime-gpu**, assurez-vous dâ€™avoir les bibliothÃ¨ques CUDA/cuDNN compatibles. Sinon, laissez lâ€™option **Piper â†’ CUDA** dÃ©sactivÃ©e et utilisez `onnxruntime` CPU.

---

## ğŸ—‚ï¸ Structure rapide

```
.
â”œâ”€â”€ app_4.py                 # Cette application Streamlit
â”œâ”€â”€ jarvis.py                # Backend audio local (appelÃ© par lâ€™UI)
â”œâ”€â”€ README.md                # (ce fichier)
â””â”€â”€ docs/
    â””â”€â”€ interface.png        # Capture dâ€™Ã©cran pour GitHub
```

---

## âš™ï¸ Configuration & Persistance

Un fichier est crÃ©Ã©/lu en **JSON** :

- **Chemin** : `~/.jarvis/ui_config.json`
- **Extrait** (valeurs par dÃ©faut) :

```jsonc
{
  "whisper": {"model": "small", "lang": "fr", "vad": true, "device": "cpu", "compute": "int8"},
  "piper": {"base_dir": "~/.jarvis/voices", "voice": "", "speaker_id": 0, "speed": 0.9,
             "noise": 0.667, "noise_w": 0.8, "sentence_silence": 0.10, "use_cuda": false},
  "ollama": {"host": "http://127.0.0.1:11434", "model": "qwen2.5:latest", "temperature": 0.7,
             "num_ctx": 4096, "stream": false},
  "mcp": {"servers": [],
           "proxy": {"enabled": true, "command": "node",
                      "args": ["/ABSOLU/adamwattis_mcp-proxy-server/build/index.js"],
                      "env": {}, "tool_timeout_s": 60, "chat_shortcuts": true,
                      "auto_web": false, "auto_web_topk": 5}},
  "jarvis": {"path": "./jarvis.py", "audio_out": "analog", "tts_engine": "piper",
             "tts_lang": "fr", "wake_word": "jarvis", "wake_aliases": "",
             "require_wake": true, "wake_fuzzy": true, "wake_fuzzy_score": 80}
}
```

Lâ€™UI exporte les principaux paramÃ¨tres en **variables dâ€™environnement** (exemples) pour le backendÂ :

- `PIPER_VOICE`, `PIPER_LENGTH`, `PIPER_NOISE`, `PIPER_NOISE_W`, `PIPER_SENT_SIL`, `PIPER_CUDA`, `PIPER_SPEAKER_ID`
- `FW_MODEL`, `FW_DEVICE`, `FW_COMPUTE`, `FW_LANGUAGE`, `FW_VAD_CMD`
- `WAKE_WORD`, `REQUIRE_WAKE`, `WAKE_FUZZY`, `WAKE_FUZZY_SCORE`, `AUDIO_OUT`
- `OLLAMA_HOST`, `LLM_ID`, `OLLAMA_TEMPERATURE`, `OLLAMA_NUM_CTX`, `OLLAMA_STREAM`
- `MCP_SERVERS_JSON`

---

## ğŸ—£ï¸ Radar vocal (HTML/JS)

Le composant est rendu via `st.components.v1.html` pour Ã©viter lâ€™Ã©chappement du SVG et autoriser lâ€™animation CSS. Il expose :

- **Mode** : `vocal` / `chat` (Ã©tiquette sous le radar)
- **Speaking** : bascule automatique pendant ~6s aprÃ¨s un message de lâ€™assistant (branchÃ© sur les logs). Vous pouvez le connecter facilement Ã  un **niveau RMS** (WebSocket ou audio worker) pour une rÃ©activitÃ© en temps rÃ©el.

---

## ğŸ” Websearch MCP (proxy)

- Lâ€™UI peut lancer un client MCP **stdio** Ã©phÃ©mÃ¨re pointant vers le **proxy** `adamwattis_mcp-proxy-server` (champ *command* = `node`, *args* = chemin absolu vers `build/index.js`).
- Renseignez lâ€™`ENV` si nÃ©cessaire (ex. `MCP_CONFIG_PATH=/ABSOLU/.../config.json`).
- Raccourcis de chat :
  - `/web requÃªte` ou `/ddg requÃªte`
  - `/fetch URL`
  - `!tool <nom> {json}`

---

## ğŸ§ª DÃ©mos rapides

- **Tester Ollama** : onglet *Ollama* â†’ *Tester connexion* / *Pull modÃ¨le* / *Warm-up*.
- **Piper** : tÃ©lÃ©versez une voix `.onnx` et (optionnellement) le `.json` associÃ©, choisissez-la dans la liste.
- **MCP** : ajoutez un serveur, dÃ©marrez-le, *Lister tools* ou *Appeler un tool*.

---

## ğŸ› ï¸ DÃ©pannage (FAQ courte)

### ONNXRuntime / CUDA introuvable (Piper)
- SymptÃ´me : erreurs `libcublasLt.so.11` ou `CUDA_PATH is set but CUDA wasnâ€™t able to be loaded`.
- Solutions :
  1) DÃ©sactiver **Piper â†’ CUDA** (CPU), ou
  2) Installer la pile CUDA/cuDNN compatible avec `onnxruntime-gpu`, ou
  3) Utiliser `onnxruntime` (CPU) au lieu de la variante GPU.

### Node ESM / `require is not defined`
- Si votre wrapper JS est traitÃ© en **ESM**, utilisez `import`/`export` ou renommez le wrapper en `.cjs`. Lâ€™UI appelle directement `build/index.js` avec `node`.

### JSONRPC: "Failed to parse" (MCP)
- VÃ©rifiez que le binaire proxy nâ€™Ã©crit **que du JSON** sur stdout (pas de lignes de log comme `Connecting to ...`).

---

## ğŸ”’ SÃ©curitÃ©

Lâ€™UI peut dÃ©marrer des **processus locaux** (MCP, Jarvis backend) et exÃ©cuter des tools via MCP. Utilisez-la sur une machine de confiance.

---

## ğŸ“ Licence

MIT â€” voir `LICENSE`.

---

## ğŸ¤ Contribuer

Issues et PR bienvenues ! Merci dâ€™indiquer votre OS, version de Python, version dâ€™Ollama, et les logs pertinents.

