# Jarvis ‚Äî UI Streamlit pour assistant vocal local

![Interface ‚Äì Jarvis UI](docs/interface.png)

Jarvis est une interface Streamlit qui pilote un assistant vocal local. Elle orchestre la reconnaissance vocale (Whisper / Faster-Whisper), la synth√®se vocale (Piper), la g√©n√©ration via Ollama et le Docker MCP Toolkit pour appeler des tools. Tout est pens√© pour un usage sur machine personnelle : aucune donn√©e ne quitte votre poste.

---

## ‚ú® Points cl√©s

- **Interface JARVIS HUD** : style holographique cyan avec avatars anim√©s, radar vocal et effets visuels futuristes
- **Topbar de statut** : visualisez en un coup d'≈ìil l'√©tat de Whisper, Piper, Ollama, Docker MCP et ONNX Runtime
- **Radar vocal anim√©** : composant HTML/JS isol√© rendu via `st.components.v1.html` qui r√©agit aux r√©ponses de l'assistant et au mode (chat ou vocal)
- **Chat enrichi** : conversation texte avec m√©moire, raccourcis `/web`, `/fetch`, `/tool` pour appeler des tools MCP
- **Mode vocal** : basculez en un clic vers une interaction mains libres, synchronis√©e avec le backend `jarvis.py`
- **Pilotage du backend local** : d√©marrez/arr√™tez `jarvis.py`, synchronisez les param√®tres (variables d'environnement) et consultez ses logs
- **Ollama int√©gr√©** : test de connectivit√©, t√©l√©chargement (`ollama pull`) et warmup de mod√®les, tool-calling natif
- **Docker MCP Toolkit** : int√©gration avec MCP servers via conteneurs Docker pour acc√®s √† des tools externes
- **Persistance automatique** : configuration sauvegard√©e sous `~/.jarvis/ui_config.json` et recharg√©e au lancement

---

## üß∞ Pr√©requis

- Python **3.11** (recommand√©)
- [Ollama](https://ollama.com/) install√© localement avec les mod√®les souhait√©s
- [Piper TTS](https://github.com/rhasspy/piper) et au moins une voix `.onnx` (copi√©e dans `~/.jarvis/voices`)
- [Docker](https://www.docker.com/) pour utiliser le Docker MCP Toolkit (optionnel mais recommand√©)
- Acc√®s audio (micro + sortie) si vous exploitez le mode vocal via `jarvis.py`

Toutes les d√©pendances Python n√©cessaires sont list√©es dans `requirements.txt` (Streamlit, Faster-Whisper, Piper-TTS, Ollama SDK, MCP SDK, etc.).

---

## üöÄ Installation rapide

```bash
# 1) Cloner le d√©p√¥t
git clone https://github.com/<votre_compte>/Streamlit_JARVIS.git
cd Streamlit_JARVIS

# 2) Cr√©er un environnement virtuel (optionnel mais recommand√©)
python -m venv .venv
source .venv/bin/activate  # sous Windows : .venv\Scripts\activate

# 3) Installer les d√©pendances Python
pip install --upgrade pip
pip install -r requirements.txt

# 4) Lancer l'interface Streamlit
streamlit run app.py
```

> üí° **CUDA / GPU** : le projet s'appuie sur `onnxruntime` CPU par d√©faut pour Piper TTS. Ollama g√®re CUDA ind√©pendamment via llama.cpp. Si vous souhaitez utiliser GPU pour Piper, installez manuellement `onnxruntime-gpu` et remplacez la d√©pendance.

---

## üóÇÔ∏è Organisation du d√©p√¥t

```
.
‚îú‚îÄ‚îÄ app.py              # Interface Streamlit principale (style JARVIS HUD)
‚îú‚îÄ‚îÄ jarvis.py           # Backend audio local (Whisper + Piper + logique vocale)
‚îú‚îÄ‚îÄ jarvis_ui_style.py  # Module CSS/HTML pour le style JARVIS HUD
‚îú‚îÄ‚îÄ requirements.txt    # D√©pendances Python
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ install_dependencies.sh
‚îÇ   ‚îú‚îÄ‚îÄ run_tests.sh
‚îÇ   ‚îî‚îÄ‚îÄ validate_gpu_setup.sh
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ interface.png
‚îú‚îÄ‚îÄ README.md           # Ce fichier
‚îú‚îÄ‚îÄ CLAUDE.md           # Instructions pour Claude Code
‚îî‚îÄ‚îÄ ANALYSE.md          # Analyse qualit√© du code
```

---

## ‚öôÔ∏è Configuration & persistance

La configuration utilisateur est stock√©e dans `~/.jarvis/ui_config.json`. Elle est fusionn√©e avec les valeurs par d√©faut et normalis√©e vers la structure Docker MCP. Exemple de contenu :

```json
{
  "whisper": {
    "model": "small",
    "lang": "fr",
    "vad": true,
    "device": "cpu",
    "compute": "int8",
    "prompt": "Transcris strictement en fran√ßais."
  },
  "piper": {
    "base_dir": "~/.jarvis/voices",
    "voice": "fr_FR-siwis-medium.onnx",
    "speaker_id": 0,
    "speed": 0.9,
    "noise": 0.667,
    "noise_w": 0.8,
    "sentence_silence": 0.1,
    "use_cuda": false
  },
  "ollama": {
    "host": "http://127.0.0.1:11434",
    "model": "qwen2.5:latest",
    "temperature": 0.7,
    "num_ctx": 4096,
    "stream": false
  },
  "llm": {
    "system_prompt": "Tu es JARVIS, un assistant francophone...",
    "use_ollama_tools": true,
    "agent_enabled": false
  },
  "mcp": {
    "docker": {
      "enabled": true,
      "docker_cmd": "docker",
      "auto_web": false,
      "auto_web_topk": 5,
      "chat_shortcuts": true
    }
  },
  "jarvis": {
    "path": "./jarvis.py",
    "audio_out": "analog",
    "tts_engine": "piper",
    "tts_lang": "fr",
    "wake_word": "jarvis",
    "wake_aliases": "",
    "require_wake": true,
    "wake_fuzzy": true,
    "wake_fuzzy_score": 80
  }
}
```

Chaque sauvegarde depuis l'UI synchronise √©galement les variables d'environnement (`FW_MODEL`, `PIPER_VOICE`, `OLLAMA_HOST`, etc.) pour le backend `jarvis.py`.

---

## üßë‚Äçüíª Utilisation

1. **Lancer l'UI** via `streamlit run app.py`
2. **Configurer les onglets "Settings"** :
   - **Whisper** : mod√®le STT, langue, VAD, device (CPU/CUDA)
   - **Piper** : voix TTS, vitesse, bruit, speaker_id
   - **Ollama** : host, mod√®le LLM, temp√©rature, contexte
   - **MCP** : activer Docker MCP, raccourcis chat, auto-web
   - **Jarvis** : chemin backend, sortie audio, wake word
3. **D√©marrer Jarvis** depuis l'onglet "Interface" (boutons d√©marrer/arr√™ter). Les logs du backend apparaissent en temps r√©el
4. **Interagir** :
   - Mode **chat** : saisissez vos messages, utilisez les raccourcis :
     - `/web <requ√™te>` : recherche web via Docker MCP
     - `/fetch <url>` : r√©cup√©rer le contenu d'une URL
     - `/tool <nom> {json}` : appeler un tool MCP directement
   - Mode **vocal** : activez le toggle, puis parlez (backend requis pour capturer l'audio et r√©pondre via Piper)
5. **Superviser** via la topbar (statuts), le radar vocal et les logs backend

---

## üîé Int√©gration Docker MCP

Le Docker MCP Toolkit permet d'utiliser des MCP servers (Model Context Protocol) via conteneurs Docker sans installation complexe.

### Configuration

- **Activ√© par d√©faut** : `mcp.docker.enabled = true`
- **Commande Docker** : `docker` (peut √™tre chemin absolu si non dans PATH)
- **Auto-web** : d√©sactiv√© par d√©faut (force le mod√®le √† choisir explicitement les tools)
- **Raccourcis chat** : activ√©s par d√©faut (`/web`, `/fetch`, `/tool`)

### Raccourcis disponibles

```bash
# Recherche web
/web Comment installer Docker sur Ubuntu

# R√©cup√©rer une page web
/fetch https://docs.docker.com

# Appeler un tool MCP directement
/tool get-library-docs {"library": "asyncio"}
```

### Pr√©requis Docker

```bash
# V√©rifier que Docker est install√©
docker --version

# Tester l'acc√®s Docker
docker ps

# Si erreur de permissions (Linux) :
sudo usermod -aG docker $USER
# Puis red√©marrer la session
```

---

## üõ†Ô∏è D√©pannage

- **Ollama KO** : v√©rifiez que `ollama serve` tourne (`app.py` peut lancer le daemon si besoin) et que l'URL correspond
- **Voix Piper introuvable** : importez vos `.onnx` via l'onglet Piper ou copiez-les dans `~/.jarvis/voices`, puis s√©lectionnez-les
- **Docker MCP injoignable** : v√©rifiez que Docker est install√© et que votre utilisateur a acc√®s au daemon Docker
- **CUDA absente** : laissez `use_cuda` d√©sactiv√© pour Piper et restez sur `onnxruntime` CPU. Ollama g√®re CUDA ind√©pendamment
- **Erreur "permission denied" Docker** : ajoutez votre utilisateur au groupe docker (voir ci-dessus)

---

## üé® Interface JARVIS HUD

L'interface utilise un style holographique inspir√© de JARVIS (Iron Man) :

- **Palette cyan/bleu** : couleurs n√©on sur fond sombre
- **Grille holographique** : effet de grille anim√©e en arri√®re-plan
- **Avatars circulaires** : avec halos lumineux et anneaux rotatifs
- **Messages chat** : bulles avec coins "bracket" style HUD
- **Radar vocal** : animation circulaire r√©agissant √† l'assistant
- **Scrollbar custom** : style JARVIS pour la fen√™tre de chat

Le style est d√©fini dans `jarvis_ui_style.py` et inject√© via `inject_jarvis_css()`.

---

## ü§ù Contribuer

Les issues et PR sont les bienvenues. Pensez √† pr√©ciser :
- OS et version Python
- Version d'Ollama
- Logs pertinents (`~/.jarvis/mcp-logs/`)
- Configuration MCP Docker (`docker ps`, `docker --version`)

---

## ‚úÖ Tests rapides

Un script minimal est fourni pour v√©rifier que les modules principaux se compilent correctement :

```bash
# Tests de syntaxe
scripts/run_tests.sh

# Ou manuellement
python -m py_compile app.py jarvis.py jarvis_ui_style.py
```

Le script √©choue imm√©diatement si la compilation d√©tecte une erreur de syntaxe.

---

## üìù Architecture technique

### Deux processus

- **app.py** (Streamlit UI) : interface utilisateur, gestion config, contr√¥le du backend
- **jarvis.py** (subprocess) : daemon audio, STT/TTS, wake word detection

### Communication

- **UI ‚Üí Backend** : variables d'environnement avant spawn
- **Backend ‚Üí UI** : logs stdout avec marqueurs `[INFO]`, `[ASSISTANT]`, `[USER]`, `[VU]`

### Stack

- **STT** : Faster-Whisper (CPU, mod√®les small/medium/large)
- **TTS** : Piper (ONNX, CPU par d√©faut, GPU optionnel)
- **LLM** : Ollama (local, CUDA via llama.cpp)
- **MCP** : Docker MCP Toolkit (conteneurs Docker)
- **UI** : Streamlit + HTML/CSS/JS custom

### Architecture hybride CPU/GPU

- **Audio/STT/TTS** : CPU (onnxruntime)
- **LLM** : GPU (Ollama g√®re CUDA ind√©pendamment)
- **Pas de conflit** : piles ONNX et CUDA s√©par√©es

---

## üìù Licence

Projet distribu√© sous licence MIT (`LICENSE`).
